# height of the bars equals to a seven day successful obs to all obs ratio
n<-(max(dat$day)-min(dat$day)+1)
res.height<-tapply(dat$ndet[dat$year==j],dat$barpos[dat$year==j],mean)
barheight[as.numeric(names(res.height))*7-3+min(dat$day)]<-res.height
# plot bars
quartz()
barplot(as.numeric(barheight[min(dat$day):max(dat$day)]),
width=1,space=0,ylim=c(0,max(res[3,])),xlab="", ylab="Detection Probability",
main=paste("J pod",j),border=NA,axes=F)
### Plot model estimates
# plot seasonal estimates of detectability p
lines(res[3,],lty=3,col=1,lwd=2.5) # lower bound of the 95% CI
lines(res[2,],lty=1,col=1,lwd=2) # median
lines(res[1,],lty=3,col=1,lwd=2.5) # upper bound of the 95% CI
axis(2)
axis(side=1,at=c(1,60,121,182,244,305,365),
labels=c("1Jan","1Mar","1May","1Jul","1Sep","1Nov","31Dec"))
}
# Add a column for total number of observations
#of all SRKWs during each week of each year year to estimate detection
#d$wkyrfa<-paste(d$Year, d$week,d$FishArea,sep="_")#if we decide to add FishArea to detection estimates for model
#d$wkyr<-paste(d$Year, d$week,sep="_")
unique(d$FishArea)
setwd("~/Documents/GitHub/fishphen")
# Load libraries
# 1. Get the data
d <- read.csv("data/AppendixII.csv")
# 2. Clean the data (also saved in output/AppendixII_cleaned,csv)
source("analyses/clean_orca.R")
#Create a new column that combines Pod and Likely Pod columna and removes spaces
d$Pod.cl<-d$Pod
#Always use Likely Pod column, when it is not blank:
d$Pod.cl[d$LikelyPod!="" & d$LikelyPod!=" "]<-d$LikelyPod[d$LikelyPod!="" & d$LikelyPod!=" "]
#perhaps also stick with Pod when LikelyPod has a "?" grep("?",d$LikelyPod,)
#remove non-orca data
d<-d[d$Pod.cl!="HB?"|d$Pod.cl!="Not Orcas",]
#Add week and day of year (day)
d$day<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"),format= "%j")
d$week<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"), format = "%V")#new weeks start on mondays
#Add a column for presences (1/0) for each pod, for Ts, and for SRKWs
d$J<-0
d$J[grep("J",d$Pod.cl)]<- 1
d$K<-0
d$K[grep("K",d$Pod.cl)]<- 1
d$L<-0
d$L[grep("L",d$Pod.cl)]<- 1
d$SRKW<-0
d$SRKW[grep("SR",d$Pod.cl)]<- 1
d$SRKW[d$J==1|d$K==1|d$L==1]<- 1
d$Orcas<-1
# Restrict analysis to only SRKWs (pods J,K,L)
#d<-d[d$SRKW==1,]#do not do this for now- perhaps this will  reduce the number of "perfect detections"?
#only data after 1978
d<-d[d$Year>1978,]
#Prepare data for running model from strebel et al 2014
#"nrep" "ndet" "site" "day" "year"
# Add a column for total number of observations
#of all SRKWs during each week of each year year to estimate detection
#d$wkyrfa<-paste(d$Year, d$week,d$FishArea,sep="_")#if we decide to add FishArea to detection estimates for model
#d$wkyr<-paste(d$Year, d$week,sep="_")
unique(d$FishArea)
# Add a column for total number of observations
#of all SRKWs during each week of each year year to estimate detection
#d$wkyrfa<-paste(d$Year, d$week,d$FishArea,sep="_")#if we decide to add FishArea to detection estimates for model
#d$wkyr<-paste(d$Year, d$week,sep="_")
sort(unique(d$FishArea))
#only using fishing areas in Washington's Salish Sea
d<-d[d$FishArea %in% c("01","02","03","04","05","06","07","09","10","11","12","13","81","82"),]#not sure where 17, 18, 19, 20, 28, 29 are...need to find out. also, where is 42583,42584
#Add week and day of year (day)
d$day<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"),format= "%j")
d$week<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"), format = "%V")#new weeks start on mondays
sort(unique(d$FishArea))
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
setwd("~/Documents/GitHub/fishphen")
# Load libraries
# 1. Get the data
d <- read.csv("data/AppendixII.csv")
# 2. Clean the data (also saved in output/AppendixII_cleaned,csv)
source("analyses/clean_orca.R")
#Create a new column that combines Pod and Likely Pod columna and removes spaces
d$Pod.cl<-d$Pod
#Always use Likely Pod column, when it is not blank:
d$Pod.cl[d$LikelyPod!="" & d$LikelyPod!=" "]<-d$LikelyPod[d$LikelyPod!="" & d$LikelyPod!=" "]
#perhaps also stick with Pod when LikelyPod has a "?" grep("?",d$LikelyPod,)
#remove non-orca data
d<-d[d$Pod.cl!="HB?"|d$Pod.cl!="Not Orcas",]
#only using fishing areas in Washington's Salish Sea
d<-d[d$FishArea %in% c("01","02","03","04","05","06","07","09","10","11","12","13","81","82"),]#not sure where 17, 18, 19, 20, 28, 29 are...need to find out. also, where is 42583,42584
#Add week and day of year (day)
d$day<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"),format= "%j")
d$week<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"), format = "%V")#new weeks start on mondays
#Add a column for presences (1/0) for each pod, for Ts, and for SRKWs
d$J<-0
d$J[grep("J",d$Pod.cl)]<- 1
d$K<-0
d$K[grep("K",d$Pod.cl)]<- 1
d$L<-0
d$L[grep("L",d$Pod.cl)]<- 1
d$SRKW<-0
d$SRKW[grep("SR",d$Pod.cl)]<- 1
d$SRKW[d$J==1|d$K==1|d$L==1]<- 1
d$Orcas<-1
# Restrict analysis to only SRKWs (pods J,K,L)
#d<-d[d$SRKW==1,]#do not do this for now- perhaps this will  reduce the number of "perfect detections"?
#only data after 1978
d<-d[d$Year>1978,]
#Prepare data for running model from strebel et al 2014
#"nrep" "ndet" "site" "day" "year"
# Add a column for total number of observations
#of all SRKWs during each week of each year year to estimate detection
#d$wkyrfa<-paste(d$Year, d$week,d$FishArea,sep="_")#if we decide to add FishArea to detection estimates for model
#d$wkyr<-paste(d$Year, d$week,sep="_")
unique(d$FishArea)
d$yrdayfa<-paste(d$Year, d$day,d$FishArea,sep="_")
#Raw detection ratios:
obs = aggregate(Orcas ~yrdayfa, data = d,sum)
# presence of each pod
js = aggregate(J ~yrdayfa, data = d,sum)
ks = aggregate(K~yrdayfa, data = d,sum)
ls = aggregate(L~yrdayfa, data = d,sum)
det<-cbind(js,ks[,2],ls[,2],obs[2])
colnames(det)[2:5]<-c("Jobs","Kobs","Lobs","nrep")
det$year<-substr(det$yrdayfa,1,4)
det$day<-substr(det$yrdayfa,6,8)
det$site<-substr(det$yrdayfa,10,nchar(det$yrdayfa))
det$site<-as.numeric(as.factor(det$site))
det$day<-as.numeric(det$day)
det$year<-as.numeric(det$year)
jdet<-subset(det,select=c(nrep,Jobs,site,day,year))
#remove any rows with 0s in them
#i.e. use only sites that have atleast 1 observation in all years
jdet <- jdet[apply(jdet, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
#jdet<- jdet[apply(jdet,1,function(row) all(row!=0)),]
kdet<-subset(det,select=c(nrep,Kobs,site,day,year))
kdet <- kdet[apply(kdet, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
ldet<-subset(det,select=c(nrep,Lobs,site,day,year))
ldet <- ldet[apply(ldet, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
colnames(jdet)[2]<-colnames(kdet)[2]<-colnames(ldet)[2]<-"ndet"
#i coudn't run model code, perhaps because some years have no observations?
#rowSums(table(jdet$site,jdet$year))#There are data in all years and all sites
#or maybe because there are 366 days in the year?
#jdet$day[jdet$day==366]<-365
write.csv(ldet,"analyses/output/l_dat.csv",row.names = FALSE)
write.csv(kdet,"analyses/output/k_dat.csv",row.names = FALSE)
write.csv(jdet,"analyses/output/j_dat.csv",row.names = FALSE)
##The below code does not work anymore
# Make Figure 1 (detectability index bar plot) for J, K, and L pod in 2017
# We will have to decide if we want detectability to vary by fishing area as well
#convert to proportion
#det$Jprop<-det$Jobs/det$totob
#det$Kprop<-det$Kobs/det$totob
#det$Lprop<-det$Lobs/det$totob
#years<-unique(det$year)
for(i in 1:length(years)){
quartz(width=9,height=4)
par(mfrow=c(1,3))
yrdet=det[det$year==years[i],]
barplot(yrdet$Jprop,names.arg=yrdet$wk, main="J")
mtext("Detectability index", side=2, line=2, cex=0.9)
mtext("Week", side=1, line=2, cex=0.9)
barplot(yrdet$Kprop,names.arg=yrdet$wk, main="K")
mtext("Week", side=1, line=2, cex=0.9)
mtext(paste(years[i]), side=1, line=3)
barplot(yrdet$Lprop,names.arg=yrdet$wk, main="L")
mtext("Week", side=1, line=2, cex=0.9)
}
# Questions about full model: what to use for J (number of days in a season)
# I think season length can vary from one year to the next
# Fit the
ldet
years<-unique(det$year)
for(i in 1:length(years)){
quartz(width=9,height=4)
par(mfrow=c(1,3))
yrdet=det[det$year==years[i],]
barplot(yrdet$Jprop,names.arg=yrdet$wk, main="J")
mtext("Detectability index", side=2, line=2, cex=0.9)
mtext("Week", side=1, line=2, cex=0.9)
barplot(yrdet$Kprop,names.arg=yrdet$wk, main="K")
mtext("Week", side=1, line=2, cex=0.9)
mtext(paste(years[i]), side=1, line=3)
barplot(yrdet$Lprop,names.arg=yrdet$wk, main="L")
mtext("Week", side=1, line=2, cex=0.9)
}
# Orca analysis: occupancy models
# Started November 1327, 2018
# by Ailene Ettinger ailene.ettinger@noo.gov
#housekeeping
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory:
setwd("~/Documents/GitHub/fishphen")
# Load libraries
# 1. Get the data
d <- read.csv("data/AppendixII.csv")
# 2. Clean the data (also saved in output/AppendixII_cleaned,csv)
source("analyses/clean_orca.R")
#Create a new column that combines Pod and Likely Pod columna and removes spaces
d$Pod.cl<-d$Pod
#Always use Likely Pod column, when it is not blank:
d$Pod.cl[d$LikelyPod!="" & d$LikelyPod!=" "]<-d$LikelyPod[d$LikelyPod!="" & d$LikelyPod!=" "]
#perhaps also stick with Pod when LikelyPod has a "?" grep("?",d$LikelyPod,)
#remove non-orca data
d<-d[d$Pod.cl!="HB?"|d$Pod.cl!="Not Orcas",]
#only using fishing areas in Washington's Salish Sea
d<-d[d$FishArea %in% c("01","02","03","04","05","06","07","09","10","11","12","13","81","82"),]#not sure where 17, 18, 19, 20, 28, 29 are...need to find out. also, where is 42583,42584
#Add week and day of year (day)
d$day<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"),format= "%j")
d$week<-strftime(strptime(paste(d$Month, d$Day, d$Year, sep="."),format= "%m.%d.%Y"), format = "%V")#new weeks start on mondays
#Add a column for presences (1/0) for each pod, for Ts, and for SRKWs
d$J<-0
d$J[grep("J",d$Pod.cl)]<- 1
d$K<-0
d$K[grep("K",d$Pod.cl)]<- 1
d$L<-0
d$L[grep("L",d$Pod.cl)]<- 1
d$SRKW<-0
d$SRKW[grep("SR",d$Pod.cl)]<- 1
d$SRKW[d$J==1|d$K==1|d$L==1]<- 1
d$Orcas<-1
# Restrict analysis to only SRKWs (pods J,K,L)
#d<-d[d$SRKW==1,]#do not do this for now- perhaps this will  reduce the number of "perfect detections"?
#only data after 1978
d<-d[d$Year>1978,]
#Prepare data for running model from strebel et al 2014
#"nrep" "ndet" "site" "day" "year"
# Add a column for total number of observations
#of all SRKWs during each week of each year year to estimate detection
#d$wkyrfa<-paste(d$Year, d$week,d$FishArea,sep="_")#if we decide to add FishArea to detection estimates for model
#d$wkyr<-paste(d$Year, d$week,sep="_")
unique(d$FishArea)
d$yrdayfa<-paste(d$Year, d$day,d$FishArea,sep="_")
#Raw detection ratios:
obs = aggregate(Orcas ~yrdayfa, data = d,sum)
# presence of each pod
js = aggregate(J ~yrdayfa, data = d,sum)
ks = aggregate(K~yrdayfa, data = d,sum)
ls = aggregate(L~yrdayfa, data = d,sum)
det<-cbind(js,ks[,2],ls[,2],obs[2])
colnames(det)[2:5]<-c("Jobs","Kobs","Lobs","nrep")
det$year<-substr(det$yrdayfa,1,4)
det$day<-substr(det$yrdayfa,6,8)
det$site<-substr(det$yrdayfa,10,nchar(det$yrdayfa))
det$site<-as.numeric(as.factor(det$site))
det$day<-as.numeric(det$day)
det$year<-as.numeric(det$year)
jdet<-subset(det,select=c(nrep,Jobs,site,day,year))
#remove any rows with 0s in them
#i.e. use only sites that have atleast 1 observation in all years
jdet <- jdet[apply(jdet, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
#jdet<- jdet[apply(jdet,1,function(row) all(row!=0)),]
kdet<-subset(det,select=c(nrep,Kobs,site,day,year))
kdet <- kdet[apply(kdet, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
ldet<-subset(det,select=c(nrep,Lobs,site,day,year))
ldet <- ldet[apply(ldet, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
colnames(jdet)[2]<-colnames(kdet)[2]<-colnames(ldet)[2]<-"ndet"
#i coudn't run model code, perhaps because some years have no observations?
#rowSums(table(jdet$site,jdet$year))#There are data in all years and all sites
#or maybe because there are 366 days in the year?
#jdet$day[jdet$day==366]<-365
write.csv(ldet,"analyses/output/l_dat.csv",row.names = FALSE)
write.csv(kdet,"analyses/output/k_dat.csv",row.names = FALSE)
write.csv(jdet,"analyses/output/j_dat.csv",row.names = FALSE)
setwd("~/Documents/GitHub/fishphen")
# Load libraries
library(R2jags)
# Specify model in BUGS language
sink("analyses/splinesSiteOcc S4.txt")
cat("
model {
### Define seasonal and annual patterns in detectability
for (m in 1:nyear) {
for (i in 1:n) {
logit(p[m,i]) <- lp[m,i]
lp[m,i] <- mfe[m,i]+mre[m,i]
mfe[m,i] <- a[m]*X[i,1]+b[m]*X[i,2]+c[m]*X[i,3]
mre[m,i]<-sum(n.mre[m,i,1:nknots])
for (k in 1:nknots) {
n.mre[m,i,k]<-b.k[m,k]*Z[i,k]
}
}
### Random regression coefficients corresponding to the truncated polynomial functions
for (k in 1:nknots) {
b.k[m,k] ~ dnorm(0,taub)
}
### Fixed regression coefficients corresponding to the 'plus' functions
a[m] ~ dnorm(0,0.01)
b[m] ~ dnorm(0,0.01)
c[m] ~ dnorm(0,0.01)
}
### precision for random regression coefficients corresponding to the truncated polynomial functions
taub~dgamma(1.0E-6,1.0E-6)
# Specify priors
for (k in 1:nyear) {
psi[k] ~ dunif(0, 1)
}
# Ecological submodel: Define state conditional on parameters
for (i in 1:nsite){
for (k in 1:nyear){
z[i,k] ~ dbern(psi[k])
}
}
# Observation model
for (i in 1:nobs){
muy[site[i],survey[i],year[i]] <- z[site[i],year[i]]*p[year[i],survey[i]]
y[i] ~ dbin(muy[site[i],survey[i],year[i]], nrep[i])
}
}
",fill = TRUE)
sink()
### Read observation data from Acrocephalus arundinaceus
dat<-read.csv("analyses/output/j_dat.csv",header=T)
### The following procedure is based on the models presented in Crainiceanu et al. 2005 and in Gimenez et al. 2006
# Degree of splines
degree <- 2
# covariate
covariate<-as.numeric(scale(range(dat$day)[1]:range(dat$day)[2]))
# covariate length
n <- length(covariate)
# location of knots
nk<-round((max(dat$day)-min(dat$day)+1)/4)
nknots<-ifelse(nk<35,nk,35)
knots<-quantile(unique(covariate),seq(0,1,length=(nknots+2))[-c(1,(nknots+2))])
# fixed effects matrix
X<-NULL
for (l in 0:degree) {
X<-cbind(X,covariate^l)
}
# random coefficients matrix
Z_K<-(abs(outer(covariate,knots,"-")))^3
OMEGA_all<-(abs(outer(knots,knots,"-")))^3
svd.OMEGA_all<-svd(OMEGA_all)
sqrt.OMEGA_all<-t(svd.OMEGA_all$v %*% (t(svd.OMEGA_all$u)*sqrt(svd.OMEGA_all$d)))
Z<-t(solve(sqrt.OMEGA_all,t(Z_K)))
# Input data
site <- dat$site
survey <- dat$day-min(dat$day)+1
nobs <- length(unique(paste(dat$site,dat$day,dat$year)))
nrep <- dat$nrep
nsite <- length(unique(dat$site))
nyear <- length(unique(dat$year))
year <- as.numeric(factor(dat$year))
zst <- array(1, dim=c(nsite,nyear))
y <- dat$ndet
# Simulation parameters
ni=5000; nc=2; nb=2500; nt=50
# List input data
jags.data <- list("site","survey","nobs","nrep","nsite","nyear","year","nknots","n","X","Z","nc", "nb", "ni", "nt","zst","y")
# Inits function
f.inits <- function(){list(a=rep(0,nyear), b=rep(0,nyear), c=rep(0,nyear), z=zst)}
# specify the parameters to be monitored
parameters <- c("a","b","c","b.k","lp","psi","taub")
jags.out<-jags.parallel(jags.data,f.inits,parameters,"splinesSiteOcc S4.txt",nc,ni,nb,nt)
# Input data
dat$site <- factor(dat$site)#move this to the dataprep file
dat$site <- droplevels(dat$site)#move this to the dataprep file
dat$site <- as.integer(dat$site)#move this to the dataprep file
site <- dat$site
survey <- dat$day-min(dat$day)+1
nobs <- length(unique(paste(dat$site,dat$day,dat$year)))
nrep <- dat$nrep
nsite <- length(unique(dat$site))
nyear <- length(unique(dat$year))
year <- as.numeric(factor(dat$year))
zst <- array(1, dim=c(nsite,nyear))
y <- dat$ndet
# Simulation parameters
ni=5000; nc=2; nb=2500; nt=50
# List input data
jags.data <- list("site","survey","nobs","nrep","nsite","nyear","year","nknots","n","X","Z","nc", "nb", "ni", "nt","zst","y")
# Inits function
f.inits <- function(){list(a=rep(0,nyear), b=rep(0,nyear), c=rep(0,nyear), z=zst)}
# specify the parameters to be monitored
parameters <- c("a","b","c","b.k","lp","psi","taub")
### Run MCMC Analysis using jags
jags.out<-jags.parallel(jags.data,f.inits,parameters,"splinesSiteOcc S4.txt",nc,ni,nb,nt)
out<-jags.out$BUGSoutput
out
findmax.fn<-function(x) {
mean(which(x==max(x)))
}
lpmax<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(lpmax)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
lpmax[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findmax.fn)
}
lpmax<-lpmax+min(dat$day)-1
lpmax[lpmax==max(dat$day)]<-NA
lpmax[lpmax==min(dat$day)]<-NA
# summarize estimates
ann.res<-array(NA, dim=c(max(dat$year)-min(dat$year)+1,3),dimnames=list(c(min(dat$year):max(dat$year)),c("mean","2.5%","97.5%")))
res<-apply(lpmax,c(2),mean,na.rm=T)
ann.res[names(res),"mean"]<-res
res<-apply(lpmax,c(2),quantile,probs=0.025,na.rm=T)
ann.res[names(res),"2.5%"]<-res
res<-apply(lpmax,c(2),quantile,probs=0.975,na.rm=T)
ann.res[names(res),"97.5%"]<-res
# get estimate of trend in date of peak detectability over years
do.lm<-function(x) {
lmres<-lm(x~as.numeric(names(x)))$coefficients
return(lmres)
}
r<-matrix(NA,dim(lpmax)[1],2)
for (o in 1:(dim(lpmax)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
#}
}
slopevec<-as.vector(r[,2])
intercept<-mean(r[,1],na.rm=T)
slope<-mean(r[,2],na.rm=T)
### Write results (in console if argument file is not specified in function cat)
cat(paste("summary results","j pod"),"\n",
paste("annual change of activity peak:", round(mean(slopevec,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec,0.025,na.rm=T),digits=2),
"to",round(quantile(slopevec,0.975,na.rm=T),digits=2)),
"\n","mean estimate of activity peak","as date",
as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-01-01",sep="")))),"\n",
sep="\n","as day of the year",
paste(rownames(ann.res),round(ann.res[,"mean"])))
#-----------------------------------------------------------------
# Plot output
#-----------------------------------------------------------------
# save plotted results as pdf
pdf(file=paste("Graphical summary S4.pdf"),width=6,height=4)
### plot estimates of peak detectability over all years
quartz()
par(mfrow=c(1,1))
par(mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n","J Pod"),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="p", col="black")
lines(x,ann.res[,"2.5%"],col="grey",lwd=2)
lines(x,ann.res[,"97.5%"],col="grey",lwd=2)
axis(side=1,at=x)
axis(side=2,at=c(60,121,182,244,305),
labels=c("1Mar","1May","1Jul","1Sep","1Nov"))
abline(a=intercept,b=slope,lty=2,col=colors()[200])
### Plot annual detectability pattern
# loop over all years
years<-sort(unique(as.numeric((dat$year))))
for (xj in 1:10) {
j<-years[xj]
# Get BUGS estimates
res.chains<-out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")]
res=plogis(apply(res.chains,MARGIN=c(length(dim(res.chains))),quantile,probs=c(.025,.5,.975)))
### Plot "naive" estimate of detectability
# prepare bars to compare barplot of observation data (bars) with estimates (line); barheight represents weekly proportion of detection events divided by all surveys
barwidth<-7
z<-1
for(m in seq(from=min(dat$day),to=max(dat$day),by=barwidth)) {
dat$barpos[dat$day >= m & dat$day < m+barwidth]<-z
z<-z+1
}
barheight<-rep(NA,times=max(dat$day)+7)
names(barheight)<-1:max(dat$day)
# height of the bars equals to a seven day successful obs to all obs ratio
n<-(max(dat$day)-min(dat$day)+1)
res.height<-tapply(dat$ndet[dat$year==j],dat$barpos[dat$year==j],mean)
barheight[as.numeric(names(res.height))*7-3+min(dat$day)]<-res.height
# plot bars
quartz()
barplot(as.numeric(barheight[min(dat$day):max(dat$day)]),
width=1,space=0,ylim=c(0,max(res[3,])),xlab="", ylab="Detection Probability",
main=paste("J pod",j),border=NA,axes=F)
### Plot model estimates
# plot seasonal estimates of detectability p
lines(res[3,],lty=3,col=1,lwd=2.5) # lower bound of the 95% CI
lines(res[2,],lty=1,col=1,lwd=2) # median
lines(res[1,],lty=3,col=1,lwd=2.5) # upper bound of the 95% CI
axis(2)
axis(side=1,at=c(1,60,121,182,244,305,365),
labels=c("1Jan","1Mar","1May","1Jul","1Sep","1Nov","31Dec"))
}
years<-sort(unique(as.numeric((dat$year))))
for (xj in 1:length(years)) {
j<-years[xj]
# Get BUGS estimates
res.chains<-out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")]
res=plogis(apply(res.chains,MARGIN=c(length(dim(res.chains))),quantile,probs=c(.025,.5,.975)))
### Plot "naive" estimate of detectability
# prepare bars to compare barplot of observation data (bars) with estimates (line); barheight represents weekly proportion of detection events divided by all surveys
barwidth<-7
z<-1
for(m in seq(from=min(dat$day),to=max(dat$day),by=barwidth)) {
dat$barpos[dat$day >= m & dat$day < m+barwidth]<-z
z<-z+1
}
barheight<-rep(NA,times=max(dat$day)+7)
names(barheight)<-1:max(dat$day)
# height of the bars equals to a seven day successful obs to all obs ratio
n<-(max(dat$day)-min(dat$day)+1)
res.height<-tapply(dat$ndet[dat$year==j],dat$barpos[dat$year==j],mean)
barheight[as.numeric(names(res.height))*7-3+min(dat$day)]<-res.height
# plot bars
quartz()
barplot(as.numeric(barheight[min(dat$day):max(dat$day)]),
width=1,space=0,ylim=c(0,max(res[3,])),xlab="", ylab="Detection Probability",
main=paste("J pod",j),border=NA,axes=F)
### Plot model estimates
# plot seasonal estimates of detectability p
lines(res[3,],lty=3,col=1,lwd=2.5) # lower bound of the 95% CI
lines(res[2,],lty=1,col=1,lwd=2) # median
lines(res[1,],lty=3,col=1,lwd=2.5) # upper bound of the 95% CI
axis(2)
axis(side=1,at=c(1,60,121,182,244,305,365),
labels=c("1Jan","1Mar","1May","1Jul","1Sep","1Nov","31Dec"))
}
save(out,file="out S4")
