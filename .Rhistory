library(rgeos)
library(mapview)
library(units)
library(scales)
library(assertthat)
library(gridExtra)
library(data.table)
library(readxl)
# load packages
library(tidyverse)
install.packages(c("sf", "tidyverse", "sp", "rgeos", "rgdal", "raster",
"units", "prioritizr", "prioritizrdata", "Rsymphony",
"mapview", "assertthat", "velox", "remotes",
"gridExtra", "data.table", "readxl", "BiocManager"))
library(tidyverse)
library(prioritizr)
library(rgdal)
library(raster)
library(rgeos)
library(mapview)
library(units)
library(scales)
library(assertthat)
library(gridExtra)
library(data.table)
library(readxl)
rm(list=ls())
options(device = ifelse(.Platform$OS.type == "windows", "windows", "quartz"))
options(stringsAsFactors = FALSE)
## libraries
library(here)
library(dplyr)
library(RColorBrewer)
library(colorRamps)
set_here("~/GitHub/cohoPSM")
## Step 1:  Read in the data/model estimates- use only predicted attributes for now
psm_pre <- read.table(here("analysis","results","PSM_predictions.txt"), header=TRUE)
rm(list=ls())
options(device = ifelse(.Platform$OS.type == "windows", "windows", "quartz"))
options(stringsAsFactors = FALSE)
## libraries
library(here)
library(dplyr)
library(RColorBrewer)
library(colorRamps)
library(dplyr)
library(yarrr)
library(vioplot)
library(colourvalues)
library(viridis)
library(shape)
library(rstan)
library(Hmisc)
library(matrixStats)
library(here)
library(leaflet)
library(rgdal)
# load functions
source(here("analysis","functions","stan_mean.R"))
source(here("analysis","functions","extract1.R"))
source(here("analysis","functions","sem_psm_predict.R"))
source(here("analysis","functions","sem_lulc_predict.R"))
source(here("analysis","functions","sem_z_crit.R"))
source(here("analysis","functions","vioplot2.R"))
# read and wrangle data
source(here("analysis","cohoPSM1_data.R"))
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory
setwd("~/Documents/GitHub/fishphen")
# Load libraries
library(R2jags)
library(scales)
install.packages("rjags")
rm(list=ls())
options(stringsAsFactors = FALSE)
# Set working directory
setwd("~/Documents/GitHub/fishphen")
# Load libraries
library(R2jags)
library(scales)
installr: install.packages("installr")
install.packages("installr")
library(installr)
updateR()
local({pkg <- select.list(sort(.packages(all.available = TRUE)),graphics=TRUE)
if(nchar(pkg)) library(pkg, character.only=TRUE)})
q()
##################################################################
# Orca phenology occupancy model, based on the
# Worked example to run the model presented in Strebel et al., 2014
# (Study of phenology by flexible estimation and modeling of seasonal detectability peaks)
# Ailene Ettinger, ailene.ettinger@noaa.gov
# (modifed from code of  Nicolas Strebel, nicolas_strebel@gmx.ch)
# Start Date:	November 27, 2018
# Title:	orca_run_occ_model
##################################################################
#housekeeping
rm(list=ls())
options(stringsAsFactorwants = FALSE)
# Set working directory
setwd("~/GitHub/fishphen")
# Load libraries
library(R2jags)
library(scales)
# Choose the data you want:
pod="J"#options= J,K,L,SR
region="ps"#options=upper salish sea (uss) or puget sound (ps)
wholeyear=FALSE #if FALSE then resitrct to assigned seasons for uss and ps
assumeSRKW=FALSE
#Choose the credible intervals you
lci<-0.25
uci<-0.75
prob<-0.5
# Read observation data from focal pod (created in orca_dataprep_occmodel.R)
if(assumeSRKW==FALSE){
if(pod=="J"){dat<-read.csv("analyses/output/j_dat.csv",header=T)}
if(pod=="K"){dat<-read.csv("analyses/output/k_dat.csv",header=T)}
if(pod=="L"){dat<-read.csv("analyses/output/l_dat.csv",header=T)}
if(pod=="SR"){dat<-read.csv("analyses/output/allsr_dat.csv",header=T)}
}
if(assumeSRKW==TRUE){
if(pod=="J"){dat<-read.csv("analyses/output/j_dat_assumeSRKW.csv",header=T)}
if(pod=="K"){dat<-read.csv("analyses/output/k_dat_assumeSRKW.csv",header=T)}
if(pod=="L"){dat<-read.csv("analyses/output/l_dat_assumeSRKW.csv",header=T)}
if(pod=="SR"){dat<-read.csv("analyses/output/allsr_dat_assumeSRKW.csv",header=T)}
}
#choose region
dat<-dat[dat$region==region,]
#Add a column for "season" and restrict data to season that is appropriate to the region
#use may 1 for uss season, oct 1 for ps season as start dates
#use oct 31 for uss season, jan31 for ps season, as end dates
if(wholeyear==FALSE & region == "ps"){
season="1"#winter
dat$season<-NA
dat$season[dat$day>182]<-1#winter (July 1-Dec 31 = >182#should extend this to Jan 31
}
#to extend to jan31, add an "orca year" which runs Apr 1-Mar 31
#dat$orcayear<-dat$year
#dat$orcayear[which(dat$day>273)]<-dat$year[which(dat$day>273)]+1
#dat$daysaftsept30<-NA
#dat$daysaftsept30[which(dat$day>273 & dat$day<367)]<-dat$day[which(dat$day>273 & dat$day<367)]-273
#dat$daysaftsept30[which(dat$day<274)]<-dat$day[which(dat$day<274)]+93#this should actually vary depending on whether or not it is a leap year
if(wholeyear==FALSE & region == "uss"){
season="2"#summer
dat$season<-NA
dat$season[dat$day>91 & dat$day<304]<-2#summer (April 1-Oct 31)
}
if(wholeyear==TRUE ){
season="3"#season 3 = whole year
dat$season<-3
}
dat<-dat[dat$season==season,]
dat <- dat[apply(dat, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
#if winter  (season 1), then days= days after sept 30
#if(season=="1"){
#  dat<-subset(dat,select=c(nrep,ndet,site, daysaftsept30,year,season,region))
#colnames(dat)[4]<-"day"
#  }
dim(dat)
#-----------------------------------------------------------------
# Codes prepare data for jags and run the analysis
#-----------------------------------------------------------------
# Specify model in BUGS language
sink("analyses/splinesSiteOccS4psi.txt")
cat("
model {
### Define seasonal and annual patterns in occurrence probability
for (m in 1:nyear) {
for (i in 1:n) {
logit(psi[m,i]) <- lp[m,i]
lp[m,i] <- mfe[m,i]+mre[m,i]
mfe[m,i] <- a[m]*X[i,1]+b[m]*X[i,2]+c[m]*X[i,3]
mre[m,i]<-sum(n.mre[m,i,1:nknots])
for (k in 1:nknots) {
n.mre[m,i,k]<-b.k[m,k]*Z[i,k]
}
}
### Random regression coefficients corresponding to the truncated polynomial functions
for (k in 1:nknots) {
b.k[m,k] ~ dnorm(0,taub)
}
### Fixed regression coefficients corresponding to the 'plus' functions
a[m] ~ dnorm(0,0.01)
b[m] ~ dnorm(0,0.01)
c[m] ~ dnorm(0,0.01)
}
### precision for random regression coefficients corresponding to the truncated polynomial functions
taub~dgamma(1.0E-6,1.0E-6)
# Specify priors for detection model
for (i in 1:nsite){#
for (y in 1:nyear) {
p[i,y] ~ dunif(0, 1)
}
}
# Ecological submodel: Define state conditional on parameters
for (y in 1:nyear) {
for (i in 1:n) {
z[y,i] ~ dbern(psi[y,i])
}
}
# Observation model
for (i in 1:nobs){
muy[site[i],survey[i],year[i]] <- z[year[i],survey[i]]*p[site[i],year[i]]
y[i] ~ dbin(muy[site[i],survey[i],year[i]], nrep[i])
}
}
",fill = TRUE)
sink()
### The following procedure is based on the models presented in Crainiceanu et al. 2005 and in Gimenez et al. 2006
# Degree of splines
degree <- 2
# covariate
covariate<-as.numeric(scale(range(dat$day)[1]:range(dat$day)[2]))
# covariate length
n <- length(covariate)
# location of knots
nk<-round((max(dat$day)-min(dat$day)+1)/4)
nknots<-ifelse(nk<35,nk,35)
knots<-quantile(unique(covariate),seq(0,1,length=(nknots+2))[-c(1,(nknots+2))])
#Note: the maximum number of knots is 35. thus, the annual model (for which nk=92 in many cases, but it is restricted to 35 by default) differs in flexibility than the seasonal model
#perhaps better to extract the seasonal peaks after fitting the whole year of data
# fixed effects matrix
X<-NULL
for (l in 0:degree) {
X<-cbind(X,covariate^l)
}
# random coefficients matrix
Z_K<-(abs(outer(covariate,knots,"-")))^3
OMEGA_all<-(abs(outer(knots,knots,"-")))^3
svd.OMEGA_all<-svd(OMEGA_all)
sqrt.OMEGA_all<-t(svd.OMEGA_all$v %*% (t(svd.OMEGA_all$u)*sqrt(svd.OMEGA_all$d)))
Z<-t(solve(sqrt.OMEGA_all,t(Z_K)))
# Input data
dat$site <- factor(dat$site)#
dat$site <- droplevels(dat$site)
fas<-sort(unique(dat$site))
dat$site <- as.integer(dat$site)
site <- dat$site
survey <- dat$day-min(dat$day)+1
nsurveys<-length(survey)
nobs <- length(unique(paste(dat$site,dat$day,dat$year)))
nrep <- dat$nrep
nsite <- length(unique(dat$site))
nyear <- length(unique(dat$year))
year <- as.numeric(factor(dat$year))
zst <- array(1, dim=c(nyear,n))
y <- dat$ndet
# Simulation parameters
#ni=15000; nc=2; nb=0; nt=10
ni=15000; nc=2; nb=8000; nt=1
# List input data
jags.data <- list("site","survey","nobs","nrep","nsite","nyear","year","nknots","n","X","Z","nc", "nb", "ni", "nt","zst","y")
# Inits function
f.inits <- function(){list(a=rep(0,nyear), b=rep(0,nyear), c=rep(0,nyear), z=zst)}
# specify the parameters to be monitored
parameters <- c("a","b","c","lp","psi","taub","p")
### Run MCMC Analysis using jags
jags.out<-jags.parallel(jags.data,f.inits,parameters,"analyses/splinesSiteOccS4psi.txt",nc,ni,nb,nt)
#names(jags.out$BUGSoutput)
#diagnose the model
#quartz()
#plot(jags.out)
#traceplot(jags.out, di
#Look at psi
out<-jags.out$BUGSoutput
jags.out$BUGSoutput$mean$psi#probability of presence (daily, across 40 years)
out
head(out$summary)
head(out$summary$Rhat)
dim(out$summary)
range(out$sumamry[,9])
range(out$summary[,9])
range(out$summary[,8])
length(which(out$summary[,8]>1.1))
length(which(out$summary[,8]>1.1))/length(out$summary[,8])
out$summary[(which(out$summary[,8]>1.1),]
out$summary[(which(out$summary[,8]>1.1)]
out$summary[(which(out$summary[,8]>1.1)),]
length(out$summary[,8])
out$summary[50:100,]
out$summary[101:150,]
tail(out$summary0
tail(out$summary)
#Look at problem fishing areas (when Rhat>1.1)
out$summary[(which(out$summary[,8]>1.1)),]
#Look at problem fishing areas (when Rhat>1.1)
names(out$summary[(which(out$summary[,8]>1.1)),])
#Look at problem fishing areas (when Rhat>1.1)
rownames(out$summary[(which(out$summary[,8]>1.1)),])
rownames(out$summary[(which(out$summary[,8]>1.1)),])
grep("psi",rownames(out$summary[(which(out$summary[,8]>1.1)),]))
rownames(out$summary[(which(out$summary[,8]>1.1)),])
rownames(out$summary[(which(out$summary[,8]>1.1)),])[grep("psi",rownames(out$summary[(which(out$summary[,8]>1.1)),]))]
#Look at problem lps
rownames(out$summary[(which(out$summary[,8]>1.1)),])[grep("lp",rownames(out$summary[(which(out$summary[,8]>1.1)),]))]
#Look at problem psis
probpsis<-rownames(out$summary[(which(out$summary[,8]>1.1)),])[grep("psi",rownames(out$summary[(which(out$summary[,8]>1.1)),]))]
#Look at problem lps
problps<-rownames(out$summary[(which(out$summary[,8]>1.1)),])[grep("lp",rownames(out$summary[(which(out$summary[,8]>1.1)),]))]
unique(substr(problps[1,5]))
unique(substr(problps,1,5))
sort(unique(substr(problps,1,5)))
head(dat)
unique(dat$site)
unique(dat$year)
length(unique(dat$year))
years<-unique(dat$year)
years[3]
years[10]
years[6]
years[14-15]
years[14:15]
years[21:22]
years[27:29]
years[31]
years[37]
probpsis
sort(unique(substr(probpsis,1,5)))
sort(unique(substr(probpsis,1,6)))
##################################################################
# Orca phenology occupancy model, based on the
# Worked example to run the model presented in Strebel et al., 2014
# (Study of phenology by flexible estimation and modeling of seasonal detectability peaks)
# Ailene Ettinger, ailene.ettinger@noaa.gov
# (modifed from code of  Nicolas Strebel, nicolas_strebel@gmx.ch)
# Start Date:	November 27, 2018
# Title:	orca_run_occ_model
##################################################################
#housekeeping
rm(list=ls())
options(stringsAsFactorwants = FALSE)
# Set working directory
setwd("~/GitHub/fishphen")
# Load libraries
library(R2jags)
library(scales)
# Choose the data you want:
pod="J"#options= J,K,L,SR
region="ps"#options=upper salish sea (uss) or puget sound (ps)
wholeyear=FALSE #if FALSE then resitrct to assigned seasons for uss and ps
assumeSRKW=FALSE
#Choose the credible intervals you
lci<-0.25
uci<-0.75
prob<-0.5
# Read observation data from focal pod (created in orca_dataprep_occmodel.R)
if(assumeSRKW==FALSE){
if(pod=="J"){dat<-read.csv("analyses/output/j_dat.csv",header=T)}
if(pod=="K"){dat<-read.csv("analyses/output/k_dat.csv",header=T)}
if(pod=="L"){dat<-read.csv("analyses/output/l_dat.csv",header=T)}
if(pod=="SR"){dat<-read.csv("analyses/output/allsr_dat.csv",header=T)}
}
if(assumeSRKW==TRUE){
if(pod=="J"){dat<-read.csv("analyses/output/j_dat_assumeSRKW.csv",header=T)}
if(pod=="K"){dat<-read.csv("analyses/output/k_dat_assumeSRKW.csv",header=T)}
if(pod=="L"){dat<-read.csv("analyses/output/l_dat_assumeSRKW.csv",header=T)}
if(pod=="SR"){dat<-read.csv("analyses/output/allsr_dat_assumeSRKW.csv",header=T)}
}
#choose region
dat<-dat[dat$region==region,]
#Add a column for "season" and restrict data to season that is appropriate to the region
#use may 1 for uss season, oct 1 for ps season as start dates
#use oct 31 for uss season, jan31 for ps season, as end dates
if(wholeyear==FALSE & region == "ps"){
season="1"#winter
dat$season<-NA
dat$season[dat$day>182]<-1#winter (July 1-Dec 31 = >182#should extend this to Jan 31
}
#to extend to jan31, add an "orca year" which runs Apr 1-Mar 31
#dat$orcayear<-dat$year
#dat$orcayear[which(dat$day>273)]<-dat$year[which(dat$day>273)]+1
#dat$daysaftsept30<-NA
#dat$daysaftsept30[which(dat$day>273 & dat$day<367)]<-dat$day[which(dat$day>273 & dat$day<367)]-273
#dat$daysaftsept30[which(dat$day<274)]<-dat$day[which(dat$day<274)]+93#this should actually vary depending on whether or not it is a leap year
if(wholeyear==FALSE & region == "uss"){
season="2"#summer
dat$season<-NA
dat$season[dat$day>91 & dat$day<304]<-2#summer (April 1-Oct 31)
}
if(wholeyear==TRUE ){
season="3"#season 3 = whole year
dat$season<-3
}
dat<-dat[dat$season==season,]
dat <- dat[apply(dat, 1, function(x) all(!is.na(x))),] # only keep rows of all not na
#if winter  (season 1), then days= days after sept 30
#if(season=="1"){
#  dat<-subset(dat,select=c(nrep,ndet,site, daysaftsept30,year,season,region))
#colnames(dat)[4]<-"day"
#  }
dim(dat)
#-----------------------------------------------------------------
# Codes prepare data for jags and run the analysis
#-----------------------------------------------------------------
# Specify model in BUGS language
sink("analyses/splinesSiteOccS4psi.txt")
cat("
model {
### Define seasonal and annual patterns in occurrence probability
for (m in 1:nyear) {
for (i in 1:n) {
logit(psi[m,i]) <- lp[m,i]
lp[m,i] <- mfe[m,i]+mre[m,i]
mfe[m,i] <- a[m]*X[i,1]+b[m]*X[i,2]+c[m]*X[i,3]
mre[m,i]<-sum(n.mre[m,i,1:nknots])
for (k in 1:nknots) {
n.mre[m,i,k]<-b.k[m,k]*Z[i,k]
}
}
### Random regression coefficients corresponding to the truncated polynomial functions
for (k in 1:nknots) {
b.k[m,k] ~ dnorm(0,taub)
}
### Fixed regression coefficients corresponding to the 'plus' functions
a[m] ~ dnorm(0,0.01)
b[m] ~ dnorm(0,0.01)
c[m] ~ dnorm(0,0.01)
}
### precision for random regression coefficients corresponding to the truncated polynomial functions
taub~dgamma(1.0E-6,1.0E-6)
# Specify priors for detection model
for (i in 1:nsite){#
for (y in 1:nyear) {
p[i,y] ~ dunif(0, 1)
}
}
# Ecological submodel: Define state conditional on parameters
for (y in 1:nyear) {
for (i in 1:n) {
z[y,i] ~ dbern(psi[y,i])
}
}
# Observation model
for (i in 1:nobs){
muy[site[i],survey[i],year[i]] <- z[year[i],survey[i]]*p[site[i],year[i]]
y[i] ~ dbin(muy[site[i],survey[i],year[i]], nrep[i])
}
}
",fill = TRUE)
sink()
### The following procedure is based on the models presented in Crainiceanu et al. 2005 and in Gimenez et al. 2006
# Degree of splines
degree <- 2
# covariate
covariate<-as.numeric(scale(range(dat$day)[1]:range(dat$day)[2]))
# covariate length
n <- length(covariate)
# location of knots
nk<-round((max(dat$day)-min(dat$day)+1)/4)
nknots<-ifelse(nk<35,nk,35)
knots<-quantile(unique(covariate),seq(0,1,length=(nknots+2))[-c(1,(nknots+2))])
#Note: the maximum number of knots is 35. thus, the annual model (for which nk=92 in many cases, but it is restricted to 35 by default) differs in flexibility than the seasonal model
#perhaps better to extract the seasonal peaks after fitting the whole year of data
# fixed effects matrix
X<-NULL
for (l in 0:degree) {
X<-cbind(X,covariate^l)
}
# random coefficients matrix
Z_K<-(abs(outer(covariate,knots,"-")))^3
OMEGA_all<-(abs(outer(knots,knots,"-")))^3
svd.OMEGA_all<-svd(OMEGA_all)
sqrt.OMEGA_all<-t(svd.OMEGA_all$v %*% (t(svd.OMEGA_all$u)*sqrt(svd.OMEGA_all$d)))
Z<-t(solve(sqrt.OMEGA_all,t(Z_K)))
# Input data
dat$site <- factor(dat$site)#
dat$site <- droplevels(dat$site)
fas<-sort(unique(dat$site))
dat$site <- as.integer(dat$site)
site <- dat$site
survey <- dat$day-min(dat$day)+1
nsurveys<-length(survey)
nobs <- length(unique(paste(dat$site,dat$day,dat$year)))
nrep <- dat$nrep
nsite <- length(unique(dat$site))
nyear <- length(unique(dat$year))
year <- as.numeric(factor(dat$year))
zst <- array(1, dim=c(nyear,n))
y <- dat$ndet
# Simulation parameters
#ni=15000; nc=2; nb=0; nt=10
ni=15000; nc=2; nb=10000; nt=1
# List input data
jags.data <- list("site","survey","nobs","nrep","nsite","nyear","year","nknots","n","X","Z","nc", "nb", "ni", "nt","zst","y")
# Inits function
f.inits <- function(){list(a=rep(0,nyear), b=rep(0,nyear), c=rep(0,nyear), z=zst)}
# specify the parameters to be monitored
parameters <- c("a","b","c","lp","psi","taub","p")
### Run MCMC Analysis using jags
jags.out<-jags.parallel(jags.data,f.inits,parameters,"analyses/splinesSiteOccS4psi.txt",nc,ni,nb,nt)
#names(jags.out$BUGSoutput)
#d
#Look at psi
out<-jags.out$BUGSoutput
jags.out$BUGSoutput$mean$psi#probability of presence (daily, across 40 years)
#Look at Rhat
range(out$summary[,8])
length(which(out$summary[,8]>1.1))/length(out$summary[,8])
nb
ni
pod
season
region
#Look at Rhat
range(out$summary[,8])
length(which(out$summary[,8]>1.1))/length(out$summary[,8])
#Look at problem fishing areas (when Rhat>1.1)
names(out$summary[(which(out$summary[,8]>1.1)),])
#Look at problem psis
probpsis<-rownames(out$summary[(which(out$summary[,8]>1.1)),])[grep("psi",rownames(out$summary[(which(out$summary[,8]>1.1)),]))]
sort(unique(substr(probpsis,1,6)))
