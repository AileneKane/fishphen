paste("confidence interval from", round(quantile(slopevec.first,0.10,na.rm=T),digits=2),
"to",round(quantile(slopevec.first,0.90,na.rm=T),digits=2)),
"\n","mean estimate of first activity doy","as date",
as.character(as.Date(x=c(ann.first[,colnames(ann.first)=="mean"]),origin=c(paste(row.names(ann.first),"-09-30",sep="")))),"\n",
sep="\n","as days after sept 30",
paste(rownames(ann.first),round(ann.first[,"mean"])))
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of last activity doy:", round(mean(slopevec.last,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec.last,0.10,na.rm=T),digits=2),
"to",round(quantile(slopevec.last,0.90,na.rm=T),digits=2)),
"\n","mean estimate of last activity doy","as date",
as.character(as.Date(x=c(ann.last[,colnames(ann.last)=="mean"]),origin=c(paste(row.names(ann.last),"-09-30",sep="")))),"\n",
sep="\n","as days after sept 30",
paste(rownames(ann.last),round(ann.last[,"mean"])))
}
if(season=="2"){
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of activity peak:", round(mean(slopevec,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec,0.10,na.rm=T),digits=2),
"to",round(quantile(slopevec,0.90,na.rm=T),digits=2)),
"\n","mean estimate of activity peak","as date",
as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-01-01",sep="")))),"\n",
sep="\n","as day of year",
paste(rownames(ann.res),round(ann.res[,"mean"])))
}
#-----------------------------------------------------------------
# Plot output
#-----------------------------------------------------------------
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen_1976_2017","_",region,"_",season,"_",pod,"_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of peak detectability over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(1,32,62,93,124,153,184,214),
labels=c("1Oct","1Nov","1Dec","1Jan","1Feb","1Mar","1Apr","1May"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod<-lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
abline(mod,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept,b=slope,col="darkred",lwd=2)
dev.off()
#
#-----------------------------------------------------------------
# Plot first date detectability >0.5
#-----------------------------------------------------------------
# save plotted results as pdf
if(pod=="J" & season=="1" & region=="uss"){pdf(file=paste("analyses/figures/J/orcaphen_1976_2017_USS_winter_Jfirst.pdf"),width=7,height=6)}
pdf(file=paste("analyses/figures/",pod,"/orcaphen_1976_2017","_",region,"_",season,"_",pod,"_first_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of peak detectability over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.first)
y=ann.first[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("First Detection Probability",prob,"\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.first, na.rm = TRUE),max(ann.first, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(274,305,335,366),
labels=c("1Oct","1Nov","1Dec","1Jan"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod.first<-lm(firstlp[o,]~as.numeric(colnames(firstlp)))$coefficients->r.first[o,]
abline(mod.first,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept.first,b=slope.first,col="darkred",lwd=2)
dev.off()
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen_1976_2017","_",region,"_",season,"_",pod,"last_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of last detectability >0.5 over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.last)
y=ann.last[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Last Detection Probability",prob,"\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.first, na.rm = TRUE),max(ann.last, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(274,305,335,366),
labels=c("1Oct","1Nov","1Dec","1Jan"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod.last<-lm(lastlp[o,]~as.numeric(colnames(lastlp)))$coefficients->r.last[o,]
abline(mod.last,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept.last,b=slope.last,col="darkred",lwd=2)
dev.off()
# Choose the data you want:
pod="J"#options= J,K,L,SR
season="2"#options= 1(winter) or 2(summer)
region="uss"#options=upper salish sea (uss) or puget sound (ps)
if(pod=="J"){dat<-read.csv("analyses/output/j_dat.csv",header=T)}
if(pod=="K"){dat<-read.csv("analyses/output/k_dat.csv",header=T)}
if(pod=="L"){dat<-read.csv("analyses/output/l_dat.csv",header=T)}
if(pod=="SR"){dat<-read.csv("analyses/output/allsr_dat.csv",header=T)}
#restrict to season
dat<-dat[dat$season==season,]
#choose region
dat<-dat[dat$region==region,]
dim(dat)
# Specify model in BUGS language
sink("analyses/splinesSiteOcc S4.txt")
cat("
model {
### Define seasonal and annual patterns in detectability
for (m in 1:nyear) {
for (i in 1:n) {
logit(p[m,i]) <- lp[m,i]
lp[m,i] <- mfe[m,i]+mre[m,i]
mfe[m,i] <- a[m]*X[i,1]+b[m]*X[i,2]+c[m]*X[i,3]
mre[m,i]<-sum(n.mre[m,i,1:nknots])
for (k in 1:nknots) {
n.mre[m,i,k]<-b.k[m,k]*Z[i,k]
}
}
### Random regression coefficients corresponding to the truncated polynomial functions
for (k in 1:nknots) {
b.k[m,k] ~ dnorm(0,taub)
}
### Fixed regression coefficients corresponding to the 'plus' functions
a[m] ~ dnorm(0,0.01)
b[m] ~ dnorm(0,0.01)
c[m] ~ dnorm(0,0.01)
}
### precision for random regression coefficients corresponding to the truncated polynomial functions
taub~dgamma(1.0E-6,1.0E-6)
# Specify priors
for (k in 1:nyear) {
psi[k] ~ dunif(0, 1)
}
# Ecological submodel: Define state conditional on parameters
for (i in 1:nsite){
for (k in 1:nyear){
z[i,k] ~ dbern(psi[k])
}
}
# Observation model
for (i in 1:nobs){
muy[site[i],survey[i],year[i]] <- z[site[i],year[i]]*p[year[i],survey[i]]
y[i] ~ dbin(muy[site[i],survey[i],year[i]], nrep[i])
}
}
",fill = TRUE)
sink()
### The following procedure is based on the models presented in Crainiceanu et al. 2005 and in Gimenez et al. 2006
# Degree of splines
degree <- 2
# covariate
covariate<-as.numeric(scale(range(dat$day)[1]:range(dat$day)[2]))
# covariate length
n <- length(covariate)
# location of knots
nk<-round((max(dat$day)-min(dat$day)+1)/4)
nknots<-ifelse(nk<35,nk,35)
knots<-quantile(unique(covariate),seq(0,1,length=(nknots+2))[-c(1,(nknots+2))])
#Note: the maximum number of nots is 35. thus, the annual model (for which nk=92 in many cases, but it is restricted to 35 by default) differs in flexibility than the seasonal model
#perhaps better to extract the seasonal peaks after fitting the whole year of data
# fixed effects matrix
X<-NULL
for (l in 0:degree) {
X<-cbind(X,covariate^l)
}
# random coefficients matrix
Z_K<-(abs(outer(covariate,knots,"-")))^3
OMEGA_all<-(abs(outer(knots,knots,"-")))^3
svd.OMEGA_all<-svd(OMEGA_all)
sqrt.OMEGA_all<-t(svd.OMEGA_all$v %*% (t(svd.OMEGA_all$u)*sqrt(svd.OMEGA_all$d)))
Z<-t(solve(sqrt.OMEGA_all,t(Z_K)))
# Input data
dat$site <- factor(dat$site)#
dat$site <- droplevels(dat$site)
dat$site <- as.integer(dat$site)
site <- dat$site
survey <- dat$day-min(dat$day)+1
nobs <- length(unique(paste(dat$site,dat$day,dat$year)))
nrep <- dat$nrep
nsite <- length(unique(dat$site))
nyear <- length(unique(dat$year))
year <- as.numeric(factor(dat$year))
zst <- array(1, dim=c(nsite,nyear))
y <- dat$ndet
# Simulation parameters
#ni=15000; nc=2; nb=0; nt=10
ni=5000; nc=2; nb=1500; nt=1
# List input data
jags.data <- list("site","survey","nobs","nrep","nsite","nyear","year","nknots","n","X","Z","nc", "nb", "ni", "nt","zst","y")
# Inits function
f.inits <- function(){list(a=rep(0,nyear), b=rep(0,nyear), c=rep(0,nyear), z=zst)}
# specify the parameters to be monitored
parameters <- c("a","b","c","lp","psi","taub")
jags.out<-jags.parallel(jags.data,f.inits,parameters,"analyses/splinesSiteOcc S4.txt",nc,ni,nb,nt)
#Look at psi
out<-jags.out$BUGSoutput
jags.out$BUGSoutput$mean$psi#probability of presence (annual)
# Save model output
if(pod=="J" & season=="1"){save(out,file="jags.output/jpod out season1")}
if(pod=="J" & season=="2"){save(out,file="jags.output/jpod out season2")}
if(pod=="K" & season=="1"){save(out,file="jags.output/kpod out season1")}
if(pod=="K" & season=="2"){save(out,file="jags.output/kpod out season2")}
if(pod=="L" & season=="1"){save(out,file="jags.output/lpod out season1")}
if(pod=="L" & season=="2"){save(out,file="jags.output/lpod out season2")}
if(pod=="SR" & season=="1"){save(out,file="jags.output/allsrpods out season1")}
if(pod=="SR" & season=="2"){save(out,file="jags.output/allsrpods out season2")}
### get estimated date of peak detectability based on posterior distribution
# get date of peak detectability in each simulation
findmax.fn<-function(x) {
mean(which(x==max(x)))
}
lpmax<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(lpmax)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
lpmax[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findmax.fn)
}
lpmax<-lpmax+min(dat$day)-1
lpmax[lpmax==max(dat$day)]<-NA
lpmax[lpmax==min(dat$day)]<-NA
#would like to Extract psi (probability of presence by day...)
dim(out$sims.list$psi)
ann.res<-array(NA, dim=c(max(dat$year)-min(dat$year)+1,3),dimnames=list(c(min(dat$year):max(dat$year)),c("mean","10%","90%")))
res<-apply(lpmax,c(2),mean,na.rm=T)
ann.res[names(res),"mean"]<-res
res<-apply(lpmax,c(2),quantile,probs=0.10,na.rm=T)
ann.res[names(res),"10%"]<-res
res<-apply(lpmax,c(2),quantile,probs=0.90,na.rm=T)
ann.res[names(res),"90%"]<-res
# get estimate of trend in date of peak detectability over years
do.lm<-function(x) {
lmres<-lm(x~as.numeric(names(x)))$coefficients
return(lmres)
}
r<-matrix(NA,dim(lpmax)[1],2)
for (o in 1:(dim(lpmax)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
#}
}
slopevec<-as.vector(r[,2])
intercept<-mean(r[,1],na.rm=T)
slope<-mean(r[,2],na.rm=T)
intercept.10<-quantile(r[,1],c(0.10),na.rm=T)
intercept.90<-quantile(r[,1],c(0.90),na.rm=T)
slope.10<-quantile(r[,2],c(0.10),na.rm=T)
slope.90<-quantile(r[,2],c(0.90),na.rm=T)
#get first date when detectability is greater than some chosen probability
prob<-0.5
findfirst.fn<-function(x) {
min(which(plogis(x)>0.5), na.rm=TRUE)
}
#check:
#count.fn<-function(x) {
#  length(which(plogis(x)<0.5))
#}
firstlp<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(firstlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
firstlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findfirst.fn)
}
firstlp<-firstlp+min(dat$day)-1
firstlp[firstlp==max(dat$day)]<-NA
firstlp[firstlp==min(dat$day)]<-NA
firstlp[which(firstlp=="Inf")]<-NA
# summarize estimates
ann.first<-array(NA, dim=c(max(dat$year)-min(dat$year)+1,3),dimnames=list(c(min(dat$year):max(dat$year)),c("mean","10%","90%")))
first<-apply(firstlp,c(2),mean,na.rm=T)
ann.first[names(first),"mean"]<-first
first<-apply(firstlp,c(2),quantile,probs=0.10,na.rm=T)
ann.first[names(first),"10%"]<-first
first<-apply(firstlp,c(2),quantile,probs=0.90,na.rm=T)
ann.first[names(first),"90%"]<-first
# get estimate of trend in date of peak detectability over years
#firstlp<-as.numeric()
r.first<-matrix(NA,dim(firstlp)[1],2)
for (o in 1:(dim(firstlp)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
y<-firstlp[o,]
y[y=="Inf"]<-NA
lm(y~as.numeric(colnames(firstlp)))$coefficients->r.first[o,]
#}
}
slopevec.first<-as.vector(r.first[,2])
intercept.first<-mean(r.first[,1],na.rm=T)
slope.first<-mean(r.first[,2],na.rm=T)
intercept.first.10<-quantile(r.first[,1],c(0.10),na.rm=T)
intercept.first.90<-quantile(r.first[,1],c(0.90),na.rm=T)
slope.first.10<-quantile(r.first[,2],c(0.10),na.rm=T)
slope.first.90<-quantile(r.first[,2],c(0.90),na.rm=T)
#get last date when detectability is greater than 0.5
findlast.fn<-function(x) {
max(which(plogis(x)>0.5), na.rm=TRUE)
}
#check:
#count.fn<-function(x) {
#  length(which(plogis(x)<0.50))
#}
lastlp<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(lastlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
lastlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findlast.fn)
}
lastlp<-lastlp+min(dat$day)-1
lastlp[lastlp==max(dat$day)]<-NA
lastlp[lastlp==min(dat$day)]<-NA
lastlp[which(lastlp=="Inf")]<-NA
lastlp[which(lastlp=="-Inf")]<-NA
# summarize estimates
ann.last<-array(NA, dim=c(max(dat$year)-min(dat$year)+1,3),dimnames=list(c(min(dat$year):max(dat$year)),c("mean","10%","90%")))
last<-apply(lastlp,c(2),mean,na.rm=T)
ann.last[names(last),"mean"]<-last
last<-apply(lastlp,c(2),quantile,probs=0.10,na.rm=T)
ann.last[names(last),"10%"]<-last
last<-apply(lastlp,c(2),quantile,probs=0.90,na.rm=T)
ann.last[names(last),"90%"]<-last
# get estimate of trend in date of peak detectability over years
#firstlp<-as.numeric()
r.last<-matrix(NA,dim(lastlp)[1],2)
for (o in 1:(dim(lastlp)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
y<-lastlp[o,]
y[y=="Inf"]<-NA
lm(y~as.numeric(colnames(lastlp)))$coefficients->r.last[o,]
#}
}
slopevec.last<-as.vector(r.last[,2])
intercept.last<-mean(r.last[,1],na.rm=T)
slope.last<-mean(r.last[,2],na.rm=T)
intercept.last.10<-quantile(r.last[,1],c(0.10),na.rm=T)
intercept.last.90<-quantile(r.last[,1],c(0.90),na.rm=T)
slope.last.10<-quantile(r.last[,2],c(0.10),na.rm=T)
slope.last.90<-quantile(r.last[,2],c(0.90),na.rm=T)
### Write results (in console if argument file is not specified in function cat)
if(season=="1"){
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of activity peak:", round(mean(slopevec,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec,0.10,na.rm=T),digits=2),
"to",round(quantile(slopevec,0.90,na.rm=T),digits=2)),
"\n","mean estimate of activity peak","as date",
as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-09-30",sep="")))),"\n",
sep="\n","as days after sept 30",
paste(rownames(ann.res),round(ann.res[,"mean"])))
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of first activity doy:", round(mean(slopevec.first,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec.first,0.10,na.rm=T),digits=2),
"to",round(quantile(slopevec.first,0.90,na.rm=T),digits=2)),
"\n","mean estimate of first activity doy","as date",
as.character(as.Date(x=c(ann.first[,colnames(ann.first)=="mean"]),origin=c(paste(row.names(ann.first),"-09-30",sep="")))),"\n",
sep="\n","as days after sept 30",
paste(rownames(ann.first),round(ann.first[,"mean"])))
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of last activity doy:", round(mean(slopevec.last,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec.last,0.10,na.rm=T),digits=2),
"to",round(quantile(slopevec.last,0.90,na.rm=T),digits=2)),
"\n","mean estimate of last activity doy","as date",
as.character(as.Date(x=c(ann.last[,colnames(ann.last)=="mean"]),origin=c(paste(row.names(ann.last),"-09-30",sep="")))),"\n",
sep="\n","as days after sept 30",
paste(rownames(ann.last),round(ann.last[,"mean"])))
}
if(season=="2"){
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of activity peak:", round(mean(slopevec,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec,0.10,na.rm=T),digits=2),
"to",round(quantile(slopevec,0.90,na.rm=T),digits=2)),
"\n","mean estimate of activity peak","as date",
as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-01-01",sep="")))),"\n",
sep="\n","as day of year",
paste(rownames(ann.res),round(ann.res[,"mean"])))
}
#-----------------------------------------------------------------
# Plot output
#-----------------------------------------------------------------
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen_1976_2017","_",region,"_",season,"_",pod,"_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of peak detectability over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(1,32,62,93,124,153,184,214),
labels=c("1Oct","1Nov","1Dec","1Jan","1Feb","1Mar","1Apr","1May"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod<-lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
abline(mod,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept,b=slope,col="darkred",lwd=2)
dev.off()
#-----------------------------------------------------------------
# Plot output
#-----------------------------------------------------------------
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen_1976_2017","_",region,"_",season,"_",pod,"_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of peak detectability over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(1,32,62,93,124,153,184,214),
labels=c("1Oct","1Nov","1Dec","1Jan","1Feb","1Mar","1Apr","1May"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod<-lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
abline(mod,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept,b=slope,col="darkred",lwd=2)
dev.off()
#
#-----------------------------------------------------------------
# Plot first date detectability >0.5
#-----------------------------------------------------------------
# save plotted results as pdf
if(pod=="J" & season=="1" & region=="uss"){pdf(file=paste("analyses/figures/J/orcaphen_1976_2017_USS_winter_Jfirst.pdf"),width=7,height=6)}
pdf(file=paste("analyses/figures/",pod,"/orcaphen_1976_2017","_",region,"_",season,"_",pod,"_first_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of peak detectability over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.first)
y=ann.first[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("First Detection Probability",prob,"\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.first, na.rm = TRUE),max(ann.first, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(274,305,335,366),
labels=c("1Oct","1Nov","1Dec","1Jan"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod.first<-lm(firstlp[o,]~as.numeric(colnames(firstlp)))$coefficients->r.first[o,]
abline(mod.first,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept.first,b=slope.first,col="darkred",lwd=2)
dev.off()
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen_1976_2017","_",region,"_",season,"_",pod,"last_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of last detectability >0.5 over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.last)
y=ann.last[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Last Detection Probability",prob,"\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.first, na.rm = TRUE),max(ann.last, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(274,305,335,366),
labels=c("1Oct","1Nov","1Dec","1Jan"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod.last<-lm(lastlp[o,]~as.numeric(colnames(lastlp)))$coefficients->r.last[o,]
abline(mod.last,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept.last,b=slope.last,col="darkred",lwd=2)
dev.off()
