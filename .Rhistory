lmres<-lm(x~as.numeric(names(x)))$coefficients
return(lmres)
}
r<-matrix(NA,dim(lpmax)[1],2)
for (o in 1:(dim(lpmax)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
#}
}
slopevec<-as.vector(r[,2])
intercept<-mean(r[,1],na.rm=T)
slope<-mean(r[,2],na.rm=T)
intercept.lci<-quantile(r[,1],c(lci),na.rm=T)
intercept.uci<-quantile(r[,1],c(uci),na.rm=T)
slope.lci<-quantile(r[,2],c(lci),na.rm=T)
slope.uci<-quantile(r[,2],c(uci),na.rm=T)
#get first date when detectability is greater than some chosen probability
prob<-0.1
findfirst.fn<-function(x) {
min(which(plogis(x)>prob), na.rm=TRUE)
}
#check:
#count.fn<-function(x) {
#  length(which(plogis(x)<prob))
#}
firstlp<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(firstlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
firstlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findfirst.fn)
}
count.fn<-function(x) {
length(which(plogis(x)<prob))
}
firstlp<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(firstlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
firstlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findfirst.fn)
}
warnings()
firstlp<-firstlp+min(dat$day)-1
min(dat$day)
min(dat$day)-1
firstlp
#check:
count.fn<-function(x) {
length(which(plogis(x)<prob))
}
firstlp<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(firstlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
firstlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findfirst.fn)
}
firstlp
firstlp<-firstlp+min(dat$day)-1
firstlp[firstlp==max(dat$day)]
findmax.fn<-function(x) {
mean(which(x==max(x)))
}
lpmax<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(lpmax)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
lpmax[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findmax.fn)
}
lpmax<-lpmax+min(dat$day)-1
lpmax[lpmax==max(dat$day)]<-NA
lpmax[lpmax==min(dat$day)]<-NA
#would like to Extract psi (probability of presence by day...)
dim(out$sims.list$psi)
# summarize estimates and look at change across the whole time series
ann.res<-array(NA, dim=c(max(dat$year)-min(dat$year)+1,3),dimnames=list(c(min(dat$year):max(dat$year)),c("mean","lci","uci")))
res<-apply(lpmax,c(2),mean,na.rm=T)
ann.res[names(res),"mean"]<-res
res<-apply(lpmax,c(2),quantile,probs=lci,na.rm=T)
ann.res[names(res),"lci"]<-res
res<-apply(lpmax,c(2),quantile,probs=uci,na.rm=T)
ann.res[names(res),"uci"]<-res
# look at change only since
# get estimate of trend in date of peak detectability over years
do.lm<-function(x) {
lmres<-lm(x~as.numeric(names(x)))$coefficients
return(lmres)
}
r<-matrix(NA,dim(lpmax)[1],2)
for (o in 1:(dim(lpmax)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
#}
}
slopevec<-as.vector(r[,2])
intercept<-mean(r[,1],na.rm=T)
slope<-mean(r[,2],na.rm=T)
intercept.lci<-quantile(r[,1],c(lci),na.rm=T)
intercept.uci<-quantile(r[,1],c(uci),na.rm=T)
slope.lci<-quantile(r[,2],c(lci),na.rm=T)
slope.uci<-quantile(r[,2],c(uci),na.rm=T)
#get first date when detectability is greater than some chosen probability
prob<-0.1
findfirst.fn<-function(x) {
min(which(plogis(x)>prob), na.rm=TRUE)
}
#check:
count.fn<-function(x) {
length(which(plogis(x)<prob))
}
firstlp<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(firstlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
firstlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findfirst.fn)
}
firstlp<-firstlp+min(dat$day)-1
#firstlp[firstlp==max(dat$day)]<-NA
#firstlp[firstlp==min(dat$day)]<-NA
firstlp[which(firstlp=="Inf")]<-NA
#firstlp<-as.numeric(firstlp)
#countlp<-array(data=NA,dim=c(out$n.sims,nyear))
#dimnames(countlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
#for (xj in sort(unique(as.numeric(factor(dat$year))))) {
#  countlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),count.fn)
#}
#returns "inf" when no estimates are >prob
# summarize estimates
ann.first<-array(NA, dim=c(max(dat$year)-min(dat$year)+1,3),dimnames=list(c(min(dat$year):max(dat$year)),c("mean","lci","uci")))
first<-apply(firstlp,c(2),mean,na.rm=T)
ann.first[names(first),"mean"]<-first
first<-apply(firstlp,c(2),quantile,probs=lci,na.rm=T)
ann.first[names(first),"lci"]<-first
first<-apply(firstlp,c(2),quantile,probs=uci,na.rm=T)
ann.first[names(first),"uci"]<-first
# get estimate of trend in date of peak detectability over years
#firstlp<-as.numeric()
r.first<-matrix(NA,dim(firstlp)[1],2)
for (o in 1:(dim(firstlp)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
y<-firstlp[o,]
y[y=="Inf"]<-NA
lm(y~as.numeric(colnames(firstlp)))$coefficients->r.first[o,]
#}
}
slopevec.first<-as.vector(r.first[,2])
intercept.first<-mean(r.first[,1],na.rm=T)
slope.first<-mean(r.first[,2],na.rm=T)
intercept.first.lci<-quantile(r.first[,1],c(lci),na.rm=T)
intercept.first.uci<-quantile(r.first[,1],c(uci),na.rm=T)
slope.first.lci<-quantile(r.first[,2],c(lci),na.rm=T)
slope.first.uci<-quantile(r.first[,2],c(uci),na.rm=T)
#get last date when detectability is greater than prob
findlast.fn<-function(x) {
max(which(plogis(x)>prob), na.rm=TRUE)
}
#check:
#count.fn<-function(x) {
#  length(which(plogis(x)<prob))
#}
lastlp<-array(data=NA,dim=c(out$n.sims,nyear))
dimnames(lastlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
for (xj in sort(unique(as.numeric(factor(dat$year))))) {
lastlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),findlast.fn)
}
lastlp<-lastlp+min(dat$day)-1
#lastlp[lastlp==max(dat$day)]<-NA
#lastlp[lastlp==min(dat$day)]<-NA
lastlp[which(lastlp=="Inf")]<-NA
lastlp[which(lastlp=="-Inf")]<-NA
#lastlp<-as.numeric(lastlp)
#countlp<-array(data=NA,dim=c(out$n.sims,nyear))
#dimnames(countlp)<-list(c(1:out$n.sims),c(sort(unique(dat$year))))
#for (xj in sort(unique(as.numeric(factor(dat$year))))) {
#  countlp[,xj]<-apply(out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")],MARGIN=c(if(out$n.chains>1) 1:2 else 1),count.fn)
#}
#returns "inf" when no estimates are >prob
# summarize estimates
ann.last<-array(NA, dim=c(max(dat$year)-min(dat$year)+1,3),dimnames=list(c(min(dat$year):max(dat$year)),c("mean","lci","uci")))
last<-apply(lastlp,c(2),mean,na.rm=T)
ann.last[names(last),"mean"]<-last
last<-apply(lastlp,c(2),quantile,probs=lci,na.rm=T)
ann.last[names(last),"lci"]<-last
last<-apply(lastlp,c(2),quantile,probs=uci,na.rm=T)
ann.last[names(last),"uci"]<-last
# get estimate of trend in date of peak detectability over years
#firstlp<-as.numeric()
r.last<-matrix(NA,dim(lastlp)[1],2)
for (o in 1:(dim(lastlp)[1])) {
# if(!is.na(sum(lpmax[o,]))) {
y<-lastlp[o,]
y[y=="Inf"]<-NA
lm(y~as.numeric(colnames(lastlp)))$coefficients->r.last[o,]
#}
}
slopevec.last<-as.vector(r.last[,2])
intercept.last<-mean(r.last[,1],na.rm=T)
slope.last<-mean(r.last[,2],na.rm=T)
intercept.last.lci<-quantile(r.last[,1],c(lci),na.rm=T)
intercept.last.uci<-quantile(r.last[,1],c(uci),na.rm=T)
slope.last.lci<-quantile(r.last[,2],c(lci),na.rm=T)
slope.last.uci<-quantile(r.last[,2],c(uci),na.rm=T)
### Write results (in console if argument file is not specified in function cat)
if(season=="1"){
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of activity peak:", round(mean(slopevec,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec,lci,na.rm=T),digits=2),
"to",round(quantile(slopevec,uci,na.rm=T),digits=2)),
"\n","mean estimate of activity peak","as date",
#as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-03-31",sep="")))),"\n",
#sep="\n","as days after mar 31",
as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-01-01",sep="")))),"\n",
sep="\n","as day of year",
paste(rownames(ann.res),round(ann.res[,"mean"])))
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of first activity doy:", round(mean(slopevec.first,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec.first,lci,na.rm=T),digits=2),
"to",round(quantile(slopevec.first,uci,na.rm=T),digits=2)),
"\n","mean estimate of first activity doy","as date",
as.character(as.Date(x=c(ann.first[,colnames(ann.first)=="mean"]),origin=c(paste(row.names(ann.first),"-01-01",sep="")))),"\n",
sep="\n","as day of year",
#as.character(as.Date(x=c(ann.first[,colnames(ann.first)=="mean"]),origin=c(paste(row.names(ann.first),"-03-31",sep="")))),"\n",
#sep="\n","as days after mar 31",
paste(rownames(ann.first),round(ann.first[,"mean"])))
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of last activity doy:", round(mean(slopevec.last,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec.last,lci,na.rm=T),digits=2),
"to",round(quantile(slopevec.last,uci,na.rm=T),digits=2)),
"\n","mean estimate of last activity doy","as date",
as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-01-01",sep="")))),"\n",
sep="\n","as day of year",
#as.character(as.Date(x=c(ann.last[,colnames(ann.last)=="mean"]),origin=c(paste(row.names(ann.last),"-03-31",sep="")))),"\n",
#sep="\n","as days after mar 31",
paste(rownames(ann.last),round(ann.last[,"mean"])))
}
if(season=="2"){
cat(paste("summary results",pod,region,season),"\n",
paste("annual change of activity peak:", round(mean(slopevec,na.rm=T),digits=2),"days"),
paste("confidence interval from", round(quantile(slopevec,lci,na.rm=T),digits=2),
"to",round(quantile(slopevec,uci,na.rm=T),digits=2)),
"\n","mean estimate of activity peak","as date",
as.character(as.Date(x=c(ann.res[,colnames(ann.res)=="mean"]),origin=c(paste(row.names(ann.res),"-01-01",sep="")))),"\n",
sep="\n","as day of year",
paste(rownames(ann.res),round(ann.res[,"mean"])))
}
#save a dataframe of trends in all three phenophases
df<-rbind(
c(pod,region,season,"peak",round(mean(slopevec,na.rm=T),digits=2),round(quantile(slopevec,lci,na.rm=T),digits=2),round(quantile(slopevec,uci,na.rm=T),digits=2)),
c(pod,region,season,"first",round(mean(slopevec.first,na.rm=T),digits=2),round(quantile(slopevec.first,lci,na.rm=T),digits=2),round(quantile(slopevec.first,uci,na.rm=T),digits=2)),
c(pod,region,season,"last",round(mean(slopevec.last,na.rm=T),digits=2),round(quantile(slopevec.last,lci,na.rm=T),digits=2),round(quantile(slopevec.last,uci,na.rm=T),digits=2))
)
colnames(df)<-c("pod","region","season","phase","slope.mn","slope.lci","slope.uci")
df.name<-paste("analyses/output/",pod,"_",season,"sept1_",region,min(dat$year),"-",max(dat$year),".csv", sep="")
write.csv(df,df.name, row.names=FALSE)
#-----------------------------------------------------------------
# Plot output
#-----------------------------------------------------------------
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen_",min(dat$year),"-",max(dat$year),"_",region,"_",season,"_",pod,"_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of peak detectability over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod<-lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
abline(mod,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept,b=slope,col="darkred",lwd=2)
dev.off()
#
#-----------------------------------------------------------------
# Plot first date detectability > selected prob
#-----------------------------------------------------------------
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen",min(dat$year),"-",max(dat$year),"_",region,"_",season,"_",pod,"_first_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of peak detectability over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.first)
y=ann.first[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("First Detection Probability",prob,"\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.first, na.rm = TRUE),max(ann.first, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod.first<-lm(firstlp[o,]~as.numeric(colnames(firstlp)))$coefficients->r.first[o,]
abline(mod.first,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept.first,b=slope.first,col="darkred",lwd=2)
dev.off()
# save plotted results as pdf
pdf(file=paste("analyses/figures/",pod,"/orcaphen",min(dat$year),"-",max(dat$year),"_",region,"_",season,"_",pod,"last_",prob,".pdf", sep=""),width=7,height=6)
### plot estimates of last detectability > selected prob over all years
#quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.last)
y=ann.last[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Last Detection Probability",prob,"\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.first, na.rm = TRUE),max(ann.last, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))
}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod.last<-lm(lastlp[o,]~as.numeric(colnames(lastlp)))$coefficients->r.last[o,]
abline(mod.last,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept.last,b=slope.last,col="darkred",lwd=2)
dev.off()
### Plot annual detectability pattern
# loop over all years
years<-sort(unique(as.numeric((dat$year))))
seasonname<-c("winter","summer")
for (xj in 1:length(years)) {
j<-years[xj]
# Get BUGS estimates
res.chains<-out$sims.array[,,paste("lp[",xj[1],",",1:(max(dat$day)-min(dat$day)+1),"]",sep="")]
res=plogis(apply(res.chains,MARGIN=c(length(dim(res.chains))),quantile,probs=c(.10,.5,.90)))
### Plot "naive" estimate of detectability
# prepare bars to compare barplot of observation data (bars) with estimates (line); barheight represents weekly proportion of detection events divided by all surveys
barwidth<-7
z<-1
for(m in seq(from=min(dat$day),to=max(dat$day),by=barwidth)) {
dat$barpos[dat$day >= m & dat$day < m+barwidth]<-z
z<-z+1
}
barheight<-rep(NA,times=max(dat$day)+7)
names(barheight)<-1:max(dat$day)
# height of the bars equals to a seven day successful obs to all obs ratio
n<-(max(dat$day)-min(dat$day)+1)
res.height<-tapply(dat$ndet[dat$year==j],dat$barpos[dat$year==j],sum)/tapply(dat$nrep[dat$year==j],dat$barpos[dat$year==j],sum)
barheight[as.numeric(names(res.height))*7-3+min(dat$day)]<-res.height
# plot bars
#for seasonal values...
figpath<- paste("analyses/figures/",pod,sep="")
figname<-paste("orcaphen",j,region,seasonname[as.numeric(season)],pod,".pdf",sep="_")
pdf(file.path(figpath, figname), width = 9, height = 6)
#quartz()
x<-barplot(as.numeric(barheight[min(dat$day):max(dat$day)]),
width=1,space=0,ylim=c(0,1),xlab="", ylab="Detection Probability",
main=paste(pod," pod",j),border=NA,axes=F)#ylim:max(res[3,])
### Plot model estimates
# plot seasonal estimates of detectability p
lines(res[3,],lty=3,col=1,lwd=2.5) # lower bound of the 90% CI
lines(res[2,],lty=1,col=1,lwd=2) # median
lines(res[1,],lty=3,col=1,lwd=2.5) # upper bound of the 90% CI
axis(2)
if(season==2){
axis(side=1,at=c(122-121,152-121,183-121,214-121,244-121,274-121),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=1,at=c(183-183-183,213-183,244-183,274-183,305-183,335-183,366-183),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))
}
dev.off()
}
uartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
#polygon(c(rev(x),x),c(rev(ann.res[,"90%"]),ann.res[,"10%"]),col=alpha("grey",0.2),lwd=0.1)
quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
#polygon(c(rev(x),x),c(rev(ann.res[,"90%"]),ann.res[,"10%"]),col=alpha("grey",0.2),lwd=0.1)
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))}
=ann.res[,"mean"]
ann.res[,"mean"]
length(y)
y[38]<-360
quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
#polygon(c(rev(x),x),c(rev(ann.res[,"90%"]),ann.res[,"10%"]),col=alpha("grey",0.2),lwd=0.1)
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod<-lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
abline(mod,col=alpha("grey",0.2),lwd=2)
#}
}
abline(a=intercept,b=slope,col="darkred",lwd=2)
quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
#polygon(c(rev(x),x),c(rev(ann.res[,"90%"]),ann.res[,"10%"]),col=alpha("grey",0.2),lwd=0.1)
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))}
quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
y[38]<-360
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="black")
#polygon(c(rev(x),x),c(rev(ann.res[,"90%"]),ann.res[,"10%"]),col=alpha("grey",0.2),lwd=0.1)
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))}
dim(lpmax)
r[o,]
intercept
slope
quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
y[38]<-360
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="salmon")
#polygon(c(rev(x),x),c(rev(ann.res[,"90%"]),ann.res[,"10%"]),col=alpha("grey",0.2),lwd=0.1)
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))}
quartz(width=7, height=6)
par(mfrow=c(1,1),mai=c(1,1,1,0.5))
x=rownames(ann.res)
y=ann.res[,"mean"]
y[38]<-360
seasname<-c("winter","summer")
plot(x,y,xlab="",ylab="",axes=F,main=paste("Peak Detection Probability","\n",pod," Pod",seasname[as.numeric(season)],region),
ylim=c(min(ann.res, na.rm = TRUE),max(ann.res, na.rm = TRUE)),pch=16,type="l", lwd=2,col="salmon")
#polygon(c(rev(x),x),c(rev(ann.res[,"90%"]),ann.res[,"10%"]),col=alpha("grey",0.2),lwd=0.1)
axis(side=1,at=x)
if(season==2){
axis(side=2,at=c(122,152,183,214,244,274),
labels=c("1May","1Jun","1Jul","1Aug","1Sept","1Oct"))
}
if(season==1){
axis(side=2,at=c(182,213,244,274,305,335,366),
labels=c("1Jul","1Aug","1Sept","1Oct","1Nov","1Dec","1Jan"))}
for (o in 1:500) {
#if(!is.na(sum(lpmax[o,]))) {
mod<-lm(lpmax[o,]~as.numeric(colnames(lpmax)))$coefficients->r[o,]
abline(mod,col=alpha("salmon",0.2),lwd=2)
#}
}
abline(a=intercept,b=slope,col="darkred",lwd=2)
abline(a=intercept,b=slope,col="darkred",lwd=2)
